{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63665a4b-5ed7-4df2-9ca5-809e9653c8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True.csv columns: ['title', 'text', 'subject', 'date']\n",
      "Fake.csv columns: ['title', 'text', 'subject', 'date']\n",
      "Real2.csv columns: ['id', 'news_url', 'title', 'tweet_ids']\n",
      "Fake2.csv columns: ['id', 'news_url', 'title', 'tweet_ids']\n",
      "Combined dataset shape: (45323, 2)\n",
      "                                                text  label\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...      1\n",
      "1  WASHINGTON (Reuters) - Transgender people will...      1\n",
      "2  WASHINGTON (Reuters) - The special counsel inv...      1\n",
      "Accuracy on test set: 0.9817981246552675\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4659\n",
      "           1       0.99      0.98      0.98      4406\n",
      "\n",
      "    accuracy                           0.98      9065\n",
      "   macro avg       0.98      0.98      0.98      9065\n",
      "weighted avg       0.98      0.98      0.98      9065\n",
      "\n",
      "Model saved as webpage_truth_model.pkl\n",
      "Prediction for sample webpage:\n",
      "Truth prediction: True\n",
      "Confidence: 0.7509340100123254\n",
      "Category: News article\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load the four datasets\n",
    "\n",
    "# For True.csv and Fake.csv, we'll use the 'text' column (if available), otherwise fallback to 'title'\n",
    "true_df = pd.read_csv('News_Dataset/True.csv')\n",
    "fake_df = pd.read_csv('News_Dataset/Fake.csv')\n",
    "\n",
    "# For Real2.csv and Fake2.csv, they only contain 'title' so we'll use that\n",
    "real2_df = pd.read_csv('addtional_training_data/Real2.csv')\n",
    "fake2_df = pd.read_csv('addtional_training_data/Fake2.csv')\n",
    "\n",
    "# Inspect which columns to use for each dataframe\n",
    "print('True.csv columns:', true_df.columns.tolist())\n",
    "print('Fake.csv columns:', fake_df.columns.tolist())\n",
    "print('Real2.csv columns:', real2_df.columns.tolist())\n",
    "print('Fake2.csv columns:', fake2_df.columns.tolist())\n",
    "\n",
    "# Define a function to extract text content from a dataframe\n",
    "# Priority: if 'text' column exists and is not empty, use it; else use 'title'\n",
    "def extract_text(df):\n",
    "    if 'text' in df.columns:\n",
    "        # Fill NaN with empty strings\n",
    "        return df['text'].fillna('')\n",
    "    else:\n",
    "        return df['title'].fillna('')\n",
    "\n",
    "# Extract the texts\n",
    "true_text = extract_text(true_df)\n",
    "fake_text = extract_text(fake_df)\n",
    "real2_text = extract_text(real2_df)\n",
    "fake2_text = extract_text(fake2_df)\n",
    "\n",
    "# Create labels for each dataset: 1 for true, 0 for fake\n",
    "true_text = true_text.copy()\n",
    "true_text = true_text.str.strip()\n",
    "\n",
    "fake_text = fake_text.copy()\n",
    "fake_text = fake_text.str.strip()\n",
    "\n",
    "real2_text = real2_text.copy()\n",
    "real2_text = real2_text.str.strip()\n",
    "\n",
    "fake2_text = fake2_text.copy()\n",
    "fake2_text = fake2_text.str.strip()\n",
    "\n",
    "# Create DataFrames with text and label\n",
    "# True news: from True.csv and Real2.csv => label 1\n",
    "# Fake news: from Fake.csv and Fake2.csv => label 0\n",
    "\n",
    "df_true = pd.DataFrame({'text': pd.concat([true_text, real2_text], ignore_index=True), 'label': 1})\n",
    "df_fake = pd.DataFrame({'text': pd.concat([fake_text, fake2_text], ignore_index=True), 'label': 0})\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_full = pd.concat([df_true, df_fake], ignore_index=True)\n",
    "\n",
    "# Drop any rows where text is empty\n",
    "df_full = df_full[df_full['text'].str.strip() != '']\n",
    "\n",
    "df_full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('Combined dataset shape:', df_full.shape)\n",
    "print(df_full.head(3))\n",
    "\n",
    "# Now we build the model pipeline using CountVectorizer with bigrams and trigrams\n",
    "# We set ngram_range=(2,3) to focus on bi- and trigrams\n",
    "\n",
    "model_pipeline_full = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(2,3))),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df_full['text']\n",
    "y = df_full['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_pipeline_full.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model_pipeline_full.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy on test set:', acc)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "with open('webpage_truth_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model_pipeline_full, model_file)\n",
    "print('Model saved as webpage_truth_model.pkl')\n",
    "\n",
    "# Define a prediction function that also flags if the text is likely not a news article\n",
    "\n",
    "def predict_webpage(text, model):\n",
    "    \"\"\"\n",
    "    Predicts the truthfulness of a webpage text.\n",
    "    Returns a tuple: (prediction, confidence, category)\n",
    "    where prediction: 0 for false, 1 for true,\n",
    "    confidence: probability associated with the predicted class,\n",
    "    and category: 'News article' if prediction confidence is above threshold, else 'Possibly not a news article'\n",
    "    \"\"\"\n",
    "    pred = model.predict([text])[0]\n",
    "    proba = model.predict_proba([text])[0]\n",
    "    confidence = proba[1] if pred == 1 else proba[0]\n",
    "    # If maximum probability is below 0.6, flag as possibly not a news article\n",
    "    if max(proba) < 0.6:\n",
    "        category = 'Possibly not a news article'\n",
    "    else:\n",
    "        category = 'News article'\n",
    "    return pred, confidence, category\n",
    "\n",
    "# Test the prediction function\n",
    "sample_text = \"Breaking news: The government has announced a new policy today affecting millions. Experts say the move will transform the economy and lower taxes. More updates to follow.\"\n",
    "pred, conf, cat = predict_webpage(sample_text, model_pipeline_full)\n",
    "print('\\\n",
    "Prediction for sample webpage:')\n",
    "print('Truth prediction:', 'True' if pred==1 else 'False')\n",
    "print('Confidence:', conf)\n",
    "print('Category:', cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3272521-1df0-4c5c-9cbc-d14e37b88696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True.csv structure:\n",
      "Columns: ['title', 'text', 'subject', 'date']\n",
      "Shape: (21417, 4)\n",
      "Sample data:\n",
      "                                               title  \\\n",
      "0  As U.S. budget fight looms, Republicans flip t...   \n",
      "1  U.S. military to accept transgender recruits o...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "\n",
      "                 date  \n",
      "0  December 31, 2017   \n",
      "1  December 29, 2017   \n",
      "--------------------------------------------------\n",
      "Fake.csv structure:\n",
      "Columns: ['title', 'text', 'subject', 'date']\n",
      "Shape: (23481, 4)\n",
      "Sample data:\n",
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Yearâ€™...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...    News   \n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "\n",
      "                date  \n",
      "0  December 31, 2017  \n",
      "1  December 31, 2017  \n",
      "--------------------------------------------------\n",
      "Real2.csv structure:\n",
      "Columns: ['id', 'news_url', 'title', 'tweet_ids']\n",
      "Shape: (624, 4)\n",
      "Sample data:\n",
      "                id                                           news_url  \\\n",
      "0  politifact14984                          http://www.nfib-sbet.org/   \n",
      "1  politifact12944  http://www.cq.com/doc/newsmakertranscripts-494...   \n",
      "\n",
      "                                         title  \\\n",
      "0  National Federation of Independent Business   \n",
      "1                  comments in Fayetteville NC   \n",
      "\n",
      "                                           tweet_ids  \n",
      "0  967132259869487105\\t967164368768196609\\t967215...  \n",
      "1  942953459\\t8980098198\\t16253717352\\t1668513250...  \n",
      "--------------------------------------------------\n",
      "Fake2.csv structure:\n",
      "Columns: ['id', 'news_url', 'title', 'tweet_ids']\n",
      "Shape: (432, 4)\n",
      "Sample data:\n",
      "                id                                           news_url  \\\n",
      "0  politifact15014          speedtalk.com/forum/viewtopic.php?t=51650   \n",
      "1  politifact15156  politics2020.info/index.php/2018/03/13/court-o...   \n",
      "\n",
      "                                               title  \\\n",
      "0  BREAKING: First NFL Team Declares Bankruptcy O...   \n",
      "1  Court Orders Obama To Pay $400 Million In Rest...   \n",
      "\n",
      "                                           tweet_ids  \n",
      "0  937349434668498944\\t937379378006282240\\t937380...  \n",
      "1  972666281441878016\\t972678396575559680\\t972827...  \n",
      "--------------------------------------------------\n",
      "Combined dataset structure:\n",
      "Number of features (n-grams): 9441505\n",
      "Sample features (first 10): ['00 000' '00 000 people' '00 0500' '00 0500 gmt' '00 0700' '00 0700 gmt'\n",
      " '00 0721' '00 0721 edt' '00 09' '00 09 occupiers']\n",
      "Classifier type: LogisticRegression\n",
      "Number of classes: 2\n",
      "Classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the structure of each file again\n",
    "import pandas as pd\n",
    "\n",
    "# Check True.csv\n",
    "print(\"True.csv structure:\")\n",
    "true_df = pd.read_csv(\"News_Dataset/True.csv\")\n",
    "print(\"Columns:\", true_df.columns.tolist())\n",
    "print(\"Shape:\", true_df.shape)\n",
    "print(\"Sample data:\")\n",
    "print(true_df.head(2))\n",
    "print(\"\\\n",
    "\" + \"-\"*50 + \"\\\n",
    "\")\n",
    "\n",
    "# Check Fake.csv\n",
    "print(\"Fake.csv structure:\")\n",
    "fake_df = pd.read_csv(\"News_Dataset/Fake.csv\")\n",
    "print(\"Columns:\", fake_df.columns.tolist())\n",
    "print(\"Shape:\", fake_df.shape)\n",
    "print(\"Sample data:\")\n",
    "print(fake_df.head(2))\n",
    "print(\"\\\n",
    "\" + \"-\"*50 + \"\\\n",
    "\")\n",
    "\n",
    "# Check Real2.csv\n",
    "print(\"Real2.csv structure:\")\n",
    "real2_df = pd.read_csv(\"addtional_training_data/Real2.csv\")\n",
    "print(\"Columns:\", real2_df.columns.tolist())\n",
    "print(\"Shape:\", real2_df.shape)\n",
    "print(\"Sample data:\")\n",
    "print(real2_df.head(2))\n",
    "print(\"\\\n",
    "\" + \"-\"*50 + \"\\\n",
    "\")\n",
    "\n",
    "# Check Fake2.csv\n",
    "print(\"Fake2.csv structure:\")\n",
    "fake2_df = pd.read_csv(\"addtional_training_data/Fake2.csv\")\n",
    "print(\"Columns:\", fake2_df.columns.tolist())\n",
    "print(\"Shape:\", fake2_df.shape)\n",
    "print(\"Sample data:\")\n",
    "print(fake2_df.head(2))\n",
    "\n",
    "# Let's also check the structure of our combined dataset\n",
    "print(\"\\\n",
    "\" + \"-\"*50 + \"\\\n",
    "\")\n",
    "print(\"Combined dataset structure:\")\n",
    "# Load the saved model to get access to the vectorizer vocabulary\n",
    "import pickle\n",
    "with open('webpage_truth_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Get information about the vectorizer\n",
    "vectorizer = model.named_steps['vect']\n",
    "print(\"Number of features (n-grams):\", len(vectorizer.get_feature_names_out()))\n",
    "print(\"Sample features (first 10):\", vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Get information about the classifier\n",
    "classifier = model.named_steps['clf']\n",
    "print(\"Classifier type:\", type(classifier).__name__)\n",
    "print(\"Number of classes:\", len(classifier.classes_))\n",
    "print(\"Classes:\", classifier.classes_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e54580-4460-4964-a6dc-3752f0cd27dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
